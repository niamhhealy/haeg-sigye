{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup library\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Import URL parser library\n",
    "import urllib2\n",
    "\n",
    "# Import Pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_last_accessed = '2017-02-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motie_headlines(motie_photo_news_url):\n",
    "\n",
    "    ''' This function takes the url of the MOTIE photo news page and returns a\n",
    "    Pandas dataframe containing the urls of the stories on the\n",
    "    page.'''\n",
    "\n",
    "    # Save HTML of MOTIE URL\n",
    "    motie_photo_news = urllib2.urlopen(motie_photo_news_url)\n",
    "\n",
    "    # Create empty list of headlines_code\n",
    "    list_of_headlines = []\n",
    "\n",
    "    # Save soup of MOTIE photo news page\n",
    "    soup = BeautifulSoup(motie_photo_news, 'html.parser')\n",
    "\n",
    "    # Get links\n",
    "    links = soup.find_all('a', attrs={'title':'Detail View'})\n",
    "\n",
    "    # Create empty list of empty list_of_links\n",
    "    list_of_links = []\n",
    "\n",
    "    # Save each link in list_of_links\n",
    "    for link in links:\n",
    "\n",
    "        list_of_links.append(str('http://english.motie.go.kr/en/pc/photonews/bbs/'+link['href']))\n",
    "\n",
    "    # Create dictionary of headlines and links\n",
    "    dictionary = {'URL':list_of_links}\n",
    "\n",
    "    # Create empty dataframe\n",
    "    headlines_urls = pd.DataFrame(data = dictionary)\n",
    "\n",
    "    return headlines_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motie_photo_news_story(story_url):\n",
    "\n",
    "    ''' This function takes a URL of a page from the MOTIE photo news section\n",
    "and returns a dataframe containing key information about that story.'''\n",
    "\n",
    "    # Save HTML of MOTIE story\n",
    "    MOTIE_photo_story = urllib2.urlopen(story_url)\n",
    "\n",
    "    # Save soup of MOTIE story\n",
    "    soup = BeautifulSoup(MOTIE_photo_story, 'html.parser')\n",
    "\n",
    "    # Save story headline\n",
    "    story_headline = soup.find('h3').get_text()\n",
    "\n",
    "    # Save story date\n",
    "    story_date = list(soup.find('h3').children)[1].get_text()\n",
    "\n",
    "    # Save story author\n",
    "    story_author = 'Republic of Korea Ministry of Trade, Industry and Energy'\n",
    "\n",
    "    # Save language\n",
    "    story_language = 'English'\n",
    "\n",
    "    # Create dictionary for story\n",
    "    story_dictionary = {'Headline':story_headline, 'Date':story_date, 'Language': story_language, 'Author':story_author, 'URL':story_url}\n",
    "\n",
    "    # Create dataframe for story\n",
    "    story_dataframe = pd.DataFrame(data = story_dictionary, index = [0])\n",
    "\n",
    "    return story_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MOTIE photo news URL\n",
    "motie_photo_news_url = 'http://english.motie.go.kr/en/pc/photonews/bbs/bbsList.do?bbs_cd_n=1'\n",
    "\n",
    "# Run MOTIE headlines function on URL + save as new dataframe\n",
    "motie_photo_news = motie_headlines(motie_photo_news_url)\n",
    "\n",
    "# Create list of URLs to find more info on\n",
    "story_URLs = motie_photo_news['URL'].tolist()\n",
    "\n",
    "# Create empty dataframe to contain further information\n",
    "stories = pd.DataFrame(data = None)\n",
    "\n",
    "# Create stories dataframe containing more information for each headline page\n",
    "for url in story_URLs:\n",
    "    story_dataframe = motie_photo_news_story(url)\n",
    "    stories = pd.concat([stories, story_dataframe])\n",
    "\n",
    "# Tidy up stories dataframe\n",
    "stories = stories.reset_index().drop(labels = 'index', axis = 1)\n",
    "\n",
    "# Merge headlines dataframe with stories dataframe\n",
    "motie_photo_news = pd.merge(stories, motie_photo_news, left_on='URL', right_on='URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fully_updated = date_last_accessed > motie_photo_news['Date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_url = story_URLs[-1]\n",
    "last_story_number = (story_URLs[-1])[68:71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "while fully_updated is False:\n",
    "    \n",
    "    last_story_number = int(last_story_number) - 1\n",
    "    next_story_url = \"http://english.motie.go.kr/en/pc/photonews/bbs/bbsList.do?bbs_seq_n={}&bbs_cd_n=1&currentPage=1&search_key_n=&search_val_v=&cate_n=\".format(last_story_number)\n",
    "    next_story_df = motie_photo_news_story(next_story_url)\n",
    "    motie_photo_news = pd.concat([motie_photo_news,next_story_df])\n",
    "    fully_updated = date_last_accessed > motie_photo_news['Date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
